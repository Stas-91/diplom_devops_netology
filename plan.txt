[0m[1mdata.yandex_client_config.client: Reading...[0m[0m
[0m[1mdata.yandex_client_config.client: Read complete after 0s [id=3543788671][0m

Terraform used the selected providers to generate the following execution
plan. Resource actions are indicated with the following symbols:
  [32m+[0m create[0m

Terraform will perform the following actions:

[1m  # docker_image.app[0m will be created
[0m  [32m+[0m[0m resource "docker_image" "app" {
      [32m+[0m[0m id          = (known after apply)
      [32m+[0m[0m image_id    = (known after apply)
      [32m+[0m[0m name        = "registry-1.docker.io/stas91/app:latest"
      [32m+[0m[0m repo_digest = (known after apply)

      [32m+[0m[0m build {
          [32m+[0m[0m cache_from     = []
          [32m+[0m[0m context        = "./../app"
          [32m+[0m[0m dockerfile     = "Dockerfile"
          [32m+[0m[0m extra_hosts    = []
          [32m+[0m[0m no_cache       = false
          [32m+[0m[0m pull_parent    = true
          [32m+[0m[0m remove         = true
          [32m+[0m[0m security_opt   = []
          [32m+[0m[0m tag            = []
            [90m# (13 unchanged attributes hidden)[0m[0m
        }
    }

[1m  # docker_registry_image.app[0m will be created
[0m  [32m+[0m[0m resource "docker_registry_image" "app" {
      [32m+[0m[0m id                   = (known after apply)
      [32m+[0m[0m insecure_skip_verify = false
      [32m+[0m[0m keep_remotely        = true
      [32m+[0m[0m name                 = "registry-1.docker.io/stas91/app:latest"
      [32m+[0m[0m sha256_digest        = (known after apply)
    }

[1m  # helm_release.kube_prometheus_stack[0m will be created
[0m  [32m+[0m[0m resource "helm_release" "kube_prometheus_stack" {
      [32m+[0m[0m atomic                     = false
      [32m+[0m[0m chart                      = "kube-prometheus-stack"
      [32m+[0m[0m cleanup_on_fail            = false
      [32m+[0m[0m create_namespace           = true
      [32m+[0m[0m dependency_update          = false
      [32m+[0m[0m disable_crd_hooks          = false
      [32m+[0m[0m disable_openapi_validation = false
      [32m+[0m[0m disable_webhooks           = false
      [32m+[0m[0m force_update               = false
      [32m+[0m[0m id                         = (known after apply)
      [32m+[0m[0m lint                       = false
      [32m+[0m[0m max_history                = 0
      [32m+[0m[0m metadata                   = (known after apply)
      [32m+[0m[0m name                       = "kube-prometheus-stack"
      [32m+[0m[0m namespace                  = "monitoring"
      [32m+[0m[0m pass_credentials           = false
      [32m+[0m[0m recreate_pods              = false
      [32m+[0m[0m render_subchart_notes      = true
      [32m+[0m[0m replace                    = false
      [32m+[0m[0m repository                 = "https://prometheus-community.github.io/helm-charts"
      [32m+[0m[0m reset_values               = false
      [32m+[0m[0m reuse_values               = false
      [32m+[0m[0m set_wo                     = (write-only attribute)
      [32m+[0m[0m skip_crds                  = false
      [32m+[0m[0m status                     = "deployed"
      [32m+[0m[0m take_ownership             = false
      [32m+[0m[0m timeout                    = 600
      [32m+[0m[0m upgrade_install            = false
      [32m+[0m[0m values                     = [
          [32m+[0m[0m <<-EOT
                prometheus:
                  enabled: true
                  prometheusSpec:
                    scrapeInterval: 30s
                    retention: 10d
                    serviceMonitorSelectorNilUsesHelmValues: false
                    resources:
                      requests:
                        memory: 1Gi
                        cpu: 500m
                      limits:
                        memory: 1Gi
                        cpu: 1
                
                alertmanager:
                  enabled: true
                  alertmanagerSpec:
                    retention: "120h"
                    resources:
                      requests:
                        memory: 1Gi
                        cpu: 200m
                      limits:
                        memory: 1Gi
                        cpu: 500m
                  config:
                    global:
                      resolve_timeout: 5m
                    route:
                      group_by: ['alertname']
                      group_wait: 30s
                      group_interval: 5m
                      repeat_interval: 12h
                      receiver: 'null'
                    receivers:
                      - name: 'null'
                
                grafana:
                  enabled: true
                  grafana.ini:
                    server:
                      root_url: "%(protocol)s://%(domain)s:%(http_port)s/"
                      serve_from_sub_path: false
                  adminPassword: "Password123"
                  service:
                    type: NodePort
                    port: 3000
                    nodePort: 30080
                  additionalDataSources:
                    - name: Prometheus
                      type: prometheus
                      url: http://kube-prometheus-stack-prometheus.monitoring.svc.cluster.local:9090
                      access: proxy
                  dashboards:
                    default:
                      k8s-cluster:
                        gnetId: 315
                        revision: 1
                        datasource: Prometheus
                      node-exporter:
                        gnetId: 3119
                        revision: 1
                        datasource: Prometheus
                
                kube-state-metrics:
                  enabled: true
                
                prometheus-node-exporter:
                  enabled: true
                
                # Добавляем ServiceMonitor для приложения
                additionalServiceMonitors:
                  - name: my-app-monitor
                    selector:
                      matchLabels:
                        app: my-app
                    namespaceSelector:
                      matchNames:
                        - default
                    endpoints:
                      - port: http
                        interval: 30s
            EOT,
        ]
      [32m+[0m[0m verify                     = false
      [32m+[0m[0m version                    = "79.0.1"
      [32m+[0m[0m wait                       = true
      [32m+[0m[0m wait_for_jobs              = false
    }

[1m  # kubernetes_deployment.my_app[0m will be created
[0m  [32m+[0m[0m resource "kubernetes_deployment" "my_app" {
      [32m+[0m[0m id               = (known after apply)
      [32m+[0m[0m wait_for_rollout = true

      [32m+[0m[0m metadata {
          [32m+[0m[0m generation       = (known after apply)
          [32m+[0m[0m name             = "my-app"
          [32m+[0m[0m namespace        = "default"
          [32m+[0m[0m resource_version = (known after apply)
          [32m+[0m[0m uid              = (known after apply)
        }

      [32m+[0m[0m spec {
          [32m+[0m[0m min_ready_seconds         = 0
          [32m+[0m[0m paused                    = false
          [32m+[0m[0m progress_deadline_seconds = 600
          [32m+[0m[0m replicas                  = "3"
          [32m+[0m[0m revision_history_limit    = 10

          [32m+[0m[0m selector {
              [32m+[0m[0m match_labels = {
                  [32m+[0m[0m "app" = "my-app"
                }
            }

          [32m+[0m[0m strategy (known after apply)

          [32m+[0m[0m template {
              [32m+[0m[0m metadata {
                  [32m+[0m[0m generation       = (known after apply)
                  [32m+[0m[0m labels           = {
                      [32m+[0m[0m "app" = "my-app"
                    }
                  [32m+[0m[0m name             = (known after apply)
                  [32m+[0m[0m resource_version = (known after apply)
                  [32m+[0m[0m uid              = (known after apply)
                }
              [32m+[0m[0m spec {
                  [32m+[0m[0m automount_service_account_token  = true
                  [32m+[0m[0m dns_policy                       = "ClusterFirst"
                  [32m+[0m[0m enable_service_links             = true
                  [32m+[0m[0m host_ipc                         = false
                  [32m+[0m[0m host_network                     = false
                  [32m+[0m[0m host_pid                         = false
                  [32m+[0m[0m hostname                         = (known after apply)
                  [32m+[0m[0m node_name                        = (known after apply)
                  [32m+[0m[0m restart_policy                   = "Always"
                  [32m+[0m[0m scheduler_name                   = (known after apply)
                  [32m+[0m[0m service_account_name             = (known after apply)
                  [32m+[0m[0m share_process_namespace          = false
                  [32m+[0m[0m termination_grace_period_seconds = 30

                  [32m+[0m[0m container {
                      [32m+[0m[0m image                      = "stas91/app:latest"
                      [32m+[0m[0m image_pull_policy          = (known after apply)
                      [32m+[0m[0m name                       = "my-app-container"
                      [32m+[0m[0m stdin                      = false
                      [32m+[0m[0m stdin_once                 = false
                      [32m+[0m[0m termination_message_path   = "/dev/termination-log"
                      [32m+[0m[0m termination_message_policy = (known after apply)
                      [32m+[0m[0m tty                        = false

                      [32m+[0m[0m port {
                          [32m+[0m[0m container_port = 80
                          [32m+[0m[0m protocol       = "TCP"
                        }

                      [32m+[0m[0m resources (known after apply)
                    }

                  [32m+[0m[0m image_pull_secrets (known after apply)

                  [32m+[0m[0m readiness_gate (known after apply)
                }
            }
        }
    }

[1m  # kubernetes_service.my_app_service[0m will be created
[0m  [32m+[0m[0m resource "kubernetes_service" "my_app_service" {
      [32m+[0m[0m id                     = (known after apply)
      [32m+[0m[0m status                 = (known after apply)
      [32m+[0m[0m wait_for_load_balancer = true

      [32m+[0m[0m metadata {
          [32m+[0m[0m generation       = (known after apply)
          [32m+[0m[0m name             = "my-app-service"
          [32m+[0m[0m namespace        = "default"
          [32m+[0m[0m resource_version = (known after apply)
          [32m+[0m[0m uid              = (known after apply)
        }

      [32m+[0m[0m spec {
          [32m+[0m[0m allocate_load_balancer_node_ports = true
          [32m+[0m[0m cluster_ip                        = (known after apply)
          [32m+[0m[0m cluster_ips                       = (known after apply)
          [32m+[0m[0m external_traffic_policy           = (known after apply)
          [32m+[0m[0m health_check_node_port            = (known after apply)
          [32m+[0m[0m internal_traffic_policy           = (known after apply)
          [32m+[0m[0m ip_families                       = (known after apply)
          [32m+[0m[0m ip_family_policy                  = (known after apply)
          [32m+[0m[0m publish_not_ready_addresses       = false
          [32m+[0m[0m selector                          = {
              [32m+[0m[0m "app" = "my-app"
            }
          [32m+[0m[0m session_affinity                  = "None"
          [32m+[0m[0m type                              = "LoadBalancer"

          [32m+[0m[0m port {
              [32m+[0m[0m node_port   = (known after apply)
              [32m+[0m[0m port        = 80
              [32m+[0m[0m protocol    = "TCP"
              [32m+[0m[0m target_port = "80"
            }

          [32m+[0m[0m session_affinity_config (known after apply)
        }
    }

[1m  # yandex_iam_service_account_static_access_key.sa-static-key[0m will be created
[0m  [32m+[0m[0m resource "yandex_iam_service_account_static_access_key" "sa-static-key" {
      [32m+[0m[0m access_key                   = (known after apply)
      [32m+[0m[0m created_at                   = (known after apply)
      [32m+[0m[0m description                  = "static access key for object storage"
      [32m+[0m[0m encrypted_secret_key         = (known after apply)
      [32m+[0m[0m id                           = (known after apply)
      [32m+[0m[0m key_fingerprint              = (known after apply)
      [32m+[0m[0m output_to_lockbox_version_id = (known after apply)
      [32m+[0m[0m secret_key                   = (sensitive value)
      [32m+[0m[0m service_account_id           = "ajelcusjb3oh3f69b88m"
    }

[1m  # yandex_kms_symmetric_key.key-a[0m will be created
[0m  [32m+[0m[0m resource "yandex_kms_symmetric_key" "key-a" {
      [32m+[0m[0m created_at          = (known after apply)
      [32m+[0m[0m default_algorithm   = "AES_128"
      [32m+[0m[0m deletion_protection = false
      [32m+[0m[0m description         = "example description"
      [32m+[0m[0m folder_id           = (known after apply)
      [32m+[0m[0m id                  = (known after apply)
      [32m+[0m[0m labels              = (known after apply)
      [32m+[0m[0m name                = "exmple-key"
      [32m+[0m[0m rotated_at          = (known after apply)
      [32m+[0m[0m rotation_period     = "8760h"
      [32m+[0m[0m status              = (known after apply)
      [32m+[0m[0m symmetric_key_id    = (known after apply)
    }

[1m  # yandex_kubernetes_cluster.my_cluster[0m will be created
[0m  [32m+[0m[0m resource "yandex_kubernetes_cluster" "my_cluster" {
      [32m+[0m[0m cluster_ipv4_range       = (known after apply)
      [32m+[0m[0m cluster_ipv6_range       = (known after apply)
      [32m+[0m[0m created_at               = (known after apply)
      [32m+[0m[0m description              = (known after apply)
      [32m+[0m[0m folder_id                = (known after apply)
      [32m+[0m[0m health                   = (known after apply)
      [32m+[0m[0m id                       = (known after apply)
      [32m+[0m[0m labels                   = {
          [32m+[0m[0m "my_key"       = "my_value"
          [32m+[0m[0m "my_other_key" = "my_other_value"
        }
      [32m+[0m[0m log_group_id             = (known after apply)
      [32m+[0m[0m name                     = (known after apply)
      [32m+[0m[0m network_id               = (known after apply)
      [32m+[0m[0m network_policy_provider  = "CALICO"
      [32m+[0m[0m node_ipv4_cidr_mask_size = 24
      [32m+[0m[0m node_service_account_id  = "ajelcusjb3oh3f69b88m"
      [32m+[0m[0m release_channel          = "STABLE"
      [32m+[0m[0m service_account_id       = "ajelcusjb3oh3f69b88m"
      [32m+[0m[0m service_ipv4_range       = (known after apply)
      [32m+[0m[0m service_ipv6_range       = (known after apply)
      [32m+[0m[0m status                   = (known after apply)

      [32m+[0m[0m kms_provider {
          [32m+[0m[0m key_id = (known after apply)
        }

      [32m+[0m[0m master {
          [32m+[0m[0m cluster_ca_certificate = (known after apply)
          [32m+[0m[0m etcd_cluster_size      = (known after apply)
          [32m+[0m[0m external_v4_address    = (known after apply)
          [32m+[0m[0m external_v4_endpoint   = (known after apply)
          [32m+[0m[0m external_v6_endpoint   = (known after apply)
          [32m+[0m[0m internal_v4_address    = (known after apply)
          [32m+[0m[0m internal_v4_endpoint   = (known after apply)
          [32m+[0m[0m public_ip              = true
          [32m+[0m[0m version                = "1.32"
          [32m+[0m[0m version_info           = (known after apply)

          [32m+[0m[0m maintenance_policy {
              [32m+[0m[0m auto_upgrade = true

              [32m+[0m[0m maintenance_window {
                  [32m+[0m[0m day        = "monday"
                  [32m+[0m[0m duration   = "3h"
                  [32m+[0m[0m start_time = "15:00"
                }
            }

          [32m+[0m[0m master_location (known after apply)

          [32m+[0m[0m master_logging {
              [32m+[0m[0m audit_enabled              = true
              [32m+[0m[0m cluster_autoscaler_enabled = true
              [32m+[0m[0m enabled                    = true
              [32m+[0m[0m events_enabled             = true
              [32m+[0m[0m folder_id                  = "b1g8kve3609ag8bp327e"
              [32m+[0m[0m kube_apiserver_enabled     = true
            }

          [32m+[0m[0m regional {
              [32m+[0m[0m region = "ru-central1"

              [32m+[0m[0m location {
                  [32m+[0m[0m subnet_id = (known after apply)
                  [32m+[0m[0m zone      = "ru-central1-a"
                }
              [32m+[0m[0m location {
                  [32m+[0m[0m subnet_id = (known after apply)
                  [32m+[0m[0m zone      = "ru-central1-b"
                }
              [32m+[0m[0m location {
                  [32m+[0m[0m subnet_id = (known after apply)
                  [32m+[0m[0m zone      = "ru-central1-d"
                }
            }

          [32m+[0m[0m scale_policy {
              [32m+[0m[0m auto_scale {
                  [32m+[0m[0m min_resource_preset_id = "s-c4-m16"
                }
            }

          [32m+[0m[0m zonal (known after apply)
        }
    }

[1m  # yandex_kubernetes_node_group.mynodegroup[0m will be created
[0m  [32m+[0m[0m resource "yandex_kubernetes_node_group" "mynodegroup" {
      [32m+[0m[0m cluster_id        = (known after apply)
      [32m+[0m[0m created_at        = (known after apply)
      [32m+[0m[0m description       = "description"
      [32m+[0m[0m id                = (known after apply)
      [32m+[0m[0m instance_group_id = (known after apply)
      [32m+[0m[0m labels            = {
          [32m+[0m[0m "key" = "value"
        }
      [32m+[0m[0m name              = "mynodegroup"
      [32m+[0m[0m status            = (known after apply)
      [32m+[0m[0m version           = "1.32"
      [32m+[0m[0m version_info      = (known after apply)

      [32m+[0m[0m allocation_policy {
          [32m+[0m[0m location {
              [32m+[0m[0m subnet_id = (known after apply)
              [32m+[0m[0m zone      = "ru-central1-a"
            }
        }

      [32m+[0m[0m deploy_policy (known after apply)

      [32m+[0m[0m instance_template {
          [32m+[0m[0m metadata                  = (known after apply)
          [32m+[0m[0m nat                       = (known after apply)
          [32m+[0m[0m network_acceleration_type = (known after apply)
          [32m+[0m[0m platform_id               = "standard-v2"

          [32m+[0m[0m boot_disk {
              [32m+[0m[0m size = 64
              [32m+[0m[0m type = "network-hdd"
            }

          [32m+[0m[0m container_network (known after apply)

          [32m+[0m[0m container_runtime {
              [32m+[0m[0m type = "containerd"
            }

          [32m+[0m[0m gpu_settings (known after apply)

          [32m+[0m[0m network_interface {
              [32m+[0m[0m ipv4       = true
              [32m+[0m[0m ipv6       = (known after apply)
              [32m+[0m[0m nat        = true
              [32m+[0m[0m subnet_ids = (known after apply)
            }

          [32m+[0m[0m resources {
              [32m+[0m[0m core_fraction = (known after apply)
              [32m+[0m[0m cores         = 2
              [32m+[0m[0m gpus          = 0
              [32m+[0m[0m memory        = 2
            }

          [32m+[0m[0m scheduling_policy {
              [32m+[0m[0m preemptible = false
            }
        }

      [32m+[0m[0m maintenance_policy {
          [32m+[0m[0m auto_repair  = true
          [32m+[0m[0m auto_upgrade = true

          [32m+[0m[0m maintenance_window {
              [32m+[0m[0m day        = "friday"
              [32m+[0m[0m duration   = "4h30m"
              [32m+[0m[0m start_time = "10:00"
            }
          [32m+[0m[0m maintenance_window {
              [32m+[0m[0m day        = "monday"
              [32m+[0m[0m duration   = "3h"
              [32m+[0m[0m start_time = "15:00"
            }
        }

      [32m+[0m[0m scale_policy {
          [32m+[0m[0m auto_scale {
              [32m+[0m[0m initial = 3
              [32m+[0m[0m max     = 6
              [32m+[0m[0m min     = 3
            }
        }
    }

[1m  # module.vpc_prod.yandex_vpc_network.network[0m will be created
[0m  [32m+[0m[0m resource "yandex_vpc_network" "network" {
      [32m+[0m[0m created_at                = (known after apply)
      [32m+[0m[0m default_security_group_id = (known after apply)
      [32m+[0m[0m folder_id                 = (known after apply)
      [32m+[0m[0m id                        = (known after apply)
      [32m+[0m[0m labels                    = (known after apply)
      [32m+[0m[0m name                      = "production"
      [32m+[0m[0m subnet_ids                = (known after apply)
    }

[1m  # module.vpc_prod.yandex_vpc_subnet.subnet["ru-central1-a"][0m will be created
[0m  [32m+[0m[0m resource "yandex_vpc_subnet" "subnet" {
      [32m+[0m[0m created_at     = (known after apply)
      [32m+[0m[0m folder_id      = (known after apply)
      [32m+[0m[0m id             = (known after apply)
      [32m+[0m[0m labels         = (known after apply)
      [32m+[0m[0m name           = "production-ru-central1-a"
      [32m+[0m[0m network_id     = (known after apply)
      [32m+[0m[0m v4_cidr_blocks = [
          [32m+[0m[0m "10.1.1.0/24",
        ]
      [32m+[0m[0m v6_cidr_blocks = (known after apply)
      [32m+[0m[0m zone           = "ru-central1-a"
    }

[1m  # module.vpc_prod.yandex_vpc_subnet.subnet["ru-central1-b"][0m will be created
[0m  [32m+[0m[0m resource "yandex_vpc_subnet" "subnet" {
      [32m+[0m[0m created_at     = (known after apply)
      [32m+[0m[0m folder_id      = (known after apply)
      [32m+[0m[0m id             = (known after apply)
      [32m+[0m[0m labels         = (known after apply)
      [32m+[0m[0m name           = "production-ru-central1-b"
      [32m+[0m[0m network_id     = (known after apply)
      [32m+[0m[0m v4_cidr_blocks = [
          [32m+[0m[0m "10.1.2.0/24",
        ]
      [32m+[0m[0m v6_cidr_blocks = (known after apply)
      [32m+[0m[0m zone           = "ru-central1-b"
    }

[1m  # module.vpc_prod.yandex_vpc_subnet.subnet["ru-central1-d"][0m will be created
[0m  [32m+[0m[0m resource "yandex_vpc_subnet" "subnet" {
      [32m+[0m[0m created_at     = (known after apply)
      [32m+[0m[0m folder_id      = (known after apply)
      [32m+[0m[0m id             = (known after apply)
      [32m+[0m[0m labels         = (known after apply)
      [32m+[0m[0m name           = "production-ru-central1-d"
      [32m+[0m[0m network_id     = (known after apply)
      [32m+[0m[0m v4_cidr_blocks = [
          [32m+[0m[0m "10.1.3.0/24",
        ]
      [32m+[0m[0m v6_cidr_blocks = (known after apply)
      [32m+[0m[0m zone           = "ru-central1-d"
    }

[1mPlan:[0m 13 to add, 0 to change, 0 to destroy.
[0m[90m
─────────────────────────────────────────────────────────────────────────────[0m

Note: You didn't use the -out option to save this plan, so Terraform can't
guarantee to take exactly these actions if you run "terraform apply" now.
